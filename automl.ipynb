{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated ML\n",
    "\n",
    "Importing all needed dependencies to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import logging\n",
    "import joblib\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.core.experiment import Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.automl.core.shared import constants\n",
    "from azureml.core.environment import Environment\n",
    "\n",
    "# Check core SDK version number\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workspace\n",
    "\n",
    "The config.json file is downloaded from Azure environment and has to be in the same folder in order for this cell to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "print(\"Workspace name: \", ws.name)\n",
    "print(\"Subscription id: \", ws.subscription_id)\n",
    "print(\"Resource group: \", ws.resource_group, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "I am creating an experiment named \"automl_heart_failure_experiment\" and a folder to hold the training scripts. The script runs will be recorded under the experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a name for experiment\n",
    "experiment_name = \"automl_heart_failure_experiment\"\n",
    "project_folder = './heart_failure-project'\n",
    "\n",
    "experiment = Experiment(ws,experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Attach an AmlCompute cluster\n",
    "For the Automl run, we need to create a compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a name for the cluster\n",
    "cpu_cluster_name = 'cluster-cpu'\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    print('Creating a new compute cluster...')\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2', min_nodes=1, max_nodes=4)\n",
    "    compute_target = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
    "\n",
    "compute_target.wait_for_completion(show_output=True)\n",
    "\n",
    "# use get_status() to get a detailed status for the current cluster. \n",
    "print(compute_target.get_status().serialize())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "The dataset contains medical records of 299 patients who had heart failure, collected during their follow-up period, where each patient profile has 13 clinical features.\n",
    "\n",
    "I am using this data in order to predict the DEATH_EVENT i.e. whether or not the patient deceased during the follow-up period (boolean).\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external.\n",
    "\n",
    "The dataset we will be using in this project is called Heart failure clinical records Data Set and is publicly available from UCI Machine Learning Repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# test to see if dataset is in store\n",
    "\n",
    "key = \"heart-failure\"\n",
    "description_text = \"Heart failure survival prediction\"\n",
    "\n",
    "\n",
    "if key in ws.datasets.keys():\n",
    "    dataset = ws.datasets[key]\n",
    "    print('The Dataset was found')\n",
    "else:\n",
    "    # Create AML Dataset and register it into Workspace\n",
    "    data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00519/heart_failure_clinical_records_dataset.csv\"\n",
    "    dataset = Dataset.Tabular.from_delimited_files(data_url)\n",
    "    #Register Dataset in Workspace\n",
    "    dataset = dataset.register(workspace = ws,name = key,description = description_text)\n",
    "\n",
    "df = dataset.to_pandas_dataframe()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of the first five rows\n",
    "print(df.head())\n",
    "\n",
    "# Explore data\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "\"experiment_timeout_minutes\": 30 - This is an exit criterion and is used to define how long, in minutes, the experiment should continue to run. To help avoid experiment time out failures, I used the value of 30 minutes.\n",
    "\n",
    "\"enable_early_stopping\": True - It defines to enable early termination if the score is not improving in the short term. In this experiment, it could also be omitted because the experiment_timeout_minutes is already defined below.\n",
    "\n",
    "\"primary_metric\": 'accuracy' - I chose accuracy as the primary metric as it is the default metric used for classification tasks.\n",
    "\n",
    "\"n_cross_validations\": 4 - This parameter sets how many cross validations to perform, based on the same number of folds (number of subsets). Is set to 4, therefore the training and validation sets will be divided into four equal sets.\n",
    "\n",
    "\"max_concurrent_iterations\": 4 - It represents the maximum number of iterations that would be executed in parallel.\n",
    "\n",
    "\"verbosity\": logging.INFO - The verbosity level for writing to the log file.\n",
    "\n",
    "task = 'classification' - This defines the experiment type which in this case is classification. Other options are regression and forecasting.\n",
    "\n",
    "training_data = dataset - the loaded dataset for the project\n",
    "\n",
    "label_column_name = 'DEATH_EVENT' - The name of the label column i.e. the target column based on which the prediction is done.\n",
    "\n",
    "featurization = 'auto' - This parameter defines whether featurization step should be done automatically as in this case (auto) or not (off).\n",
    "\n",
    "debug_log = 'automl_errors.log - The log file to write debug information to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\" : 30,\n",
    "    \"enable_early_stopping\" : True,\n",
    "    \"primary_metric\":'accuracy',\n",
    "    \"n_cross_validations\":4,\n",
    "    \"max_concurrent_iterations\":4,\n",
    "    \"verbosity\": logging.INFO\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(compute_target = compute_target,\n",
    "                            task = 'classification',\n",
    "                            training_data=dataset,\n",
    "                            path = project_folder,\n",
    "                            label_column_name=\"DEATH_EVENT\",\n",
    "                            featurization= 'auto',\n",
    "                            debug_log = \"automl_errors.log\",\n",
    "                            **automl_settings\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Submit your experiment\n",
    "remote_run = experiment.submit(automl_config, show_output=True)\n",
    "remote_run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_status()\n",
    "# Fetch the latest status of the run. It should show 'Completed'\n",
    "\n",
    "print(\"Run Status: \",remote_run.get_status())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion (show_output = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "In the cell below, get the best model from the automl experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run,fitted_model = remote_run.get_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best run\n",
    "\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_metrics()\n",
    "print(best_run.get_metrics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_details()\n",
    "print(best_run.get_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_properties()\n",
    "print(best_run.get_properties())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_run.register_model(model_name = 'automl-best-model.pkl',model_path = './outputs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run.get_file_names()\n",
    "\n",
    "# Download the yaml file that includes the environment dependencies\n",
    "best_run.download_file('outputs/conda_env_v_1_0_0.yml', 'env.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Download the model file\n",
    "\n",
    "best_run.download_file('outputs/model.pkl', 'Automl_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained but you still need to register both the models. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Registring the best model\n",
    "model = remote_run.register_model(model_name='automl-best-model.pkl')\n",
    "print(remote_run.model_id)\n",
    "\n",
    "# Get automl environment with its dependencies\n",
    "environment = Environment.get(ws, \"AzureML-AutoML\")\n",
    "\n",
    "environment = best_run.get_environment()\n",
    "entry_script='inference/scoring.py'\n",
    "best_run.download_file('outputs/scoring_file_v_1_0_0.py', entry_script)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script = entry_script, environment = environment)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, \n",
    "                                                    memory_gb = 1, \n",
    "                                                    auth_enabled= True, \n",
    "                                                    enable_app_insights= True)\n",
    "\n",
    "service = Model.deploy(ws, \"aciservice\", [model], inference_config, deployment_config)\n",
    "service.wait_for_deployment(show_output = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the service state\n",
    "# The scorig URI & the primary authentication key are copied to the endpoint.py file in order to test the deployed service.\n",
    "# The Swagger URI can be used in Swagger UI: https://petstore.swagger.io/ For more info, please see the relevant part in the README file.\n",
    "\n",
    "# Authentication is enabled, so I use the get_keys method to retrieve the primary and secondary authentication keys:\n",
    "primary, secondary = service.get_keys()\n",
    "\n",
    "print('Service state: ' + service.state)\n",
    "print('Service scoring URI: ' + service.scoring_uri)\n",
    "print('Service Swagger URI: ' + service.swagger_uri)\n",
    "print('Service primary authentication key: ' + primary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%run endpoint.py\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# URL for the web service, should be similar to:\n",
    "\n",
    "scoring_uri = ''\n",
    "\n",
    "# If the service is authenticated, set the key or token\n",
    "\n",
    "key = ''\n",
    "\n",
    "data = {\"data\":\n",
    "        [\n",
    "          {\n",
    "           \"age\": 60, \n",
    "           \"anaemia\": 1, \n",
    "           \"creatinine_phosphokinase\": 315, \n",
    "           \"diabetes\": 1, \n",
    "           \"ejection_fraction\": 60, \n",
    "           \"high_blood_pressure\": 0, \n",
    "           \"platelets\": 454000, \n",
    "           \"serum_creatinine\": 1.1, \n",
    "           \"serum_sodium\": 131, \n",
    "           \"sex\": 1, \n",
    "           \"smoking\": 1,\n",
    "           \"time\": 10\n",
    "          },\n",
    "          {\n",
    "           \"age\": 55, \n",
    "           \"anaemia\": 0, \n",
    "           \"creatinine_phosphokinase\": 1820, \n",
    "           \"diabetes\": 0, \n",
    "           \"ejection_fraction\": 38, \n",
    "           \"high_blood_pressure\": 0, \n",
    "           \"platelets\": 270000, \n",
    "           \"serum_creatinine\": 1.2, \n",
    "           \"serum_sodium\": 139, \n",
    "           \"sex\": 0, \n",
    "           \"smoking\": 0,\n",
    "           \"time\": 271\n",
    "          },\n",
    "      ]\n",
    "    }\n",
    "# Convert to JSON string\n",
    "input_data = json.dumps(data)\n",
    "with open(\"data.json\", \"w\") as _f:\n",
    "    _f.write(input_data)\n",
    "\n",
    "# Set the content type\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "# If authentication is enabled, set the authorization header\n",
    "headers['Authorization'] = f'Bearer {key}'\n",
    "\n",
    "\n",
    "# Make the request and display the response\n",
    "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
    "print(resp.json())\n",
    "print(\"Expected result: [true, false], where 'true' means '1' and 'false' means '0' as result in the 'DEATH_EVENT' column\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Printing the logs\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting the service\n",
    "Putting the deletion of the service in a separate cell to avoid accidentally running the cell before finishing the tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Submission Checklist**\n",
    "- I have registered the model.\n",
    "- I have deployed the model with the best accuracy as a webservice.\n",
    "- I have tested the webservice by sending a request to the model endpoint.\n",
    "- I have deleted the webservice and shutdown all the computes that I have used.\n",
    "- I have taken a screenshot showing the model endpoint as active.\n",
    "- The project includes a file containing the environment details.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
